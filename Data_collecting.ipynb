{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twarc\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"\"\"@ICRC_Nairobi\n",
    "@ICRC_library\n",
    "@RedCrossLebanon\n",
    "@RedCross\n",
    "@BritishRedCross\n",
    "@RedCrossAU\n",
    "@irishredcross\n",
    "@philredcross\n",
    "@IFRC_Europe\n",
    "@NepalRedCross\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscript=open(\"download/download.sh\",'w')\n",
    "for ind,org in enumerate(s.split('\\n')):\n",
    "    fngo=open(\"download/ngos{0}.txt\".format(ind),'w')\n",
    "    fngo.write(org.replace(\"@\",\"\"))\n",
    "    fngo.close()\n",
    "    fscript.write(\"twarc2 timelines --use-search download/ngos{0}.txt download{1}.jsonl\\n\".format(ind,org.replace(\"@\",\"\")))\n",
    "fscript.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %sh download.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscript=open(\"dehydrate/dehydrate.sh\",'w')\n",
    "for file in os.listdir('download'):\n",
    "    if file.split('.')[1]=='jsonl':\n",
    "        fscript.write(\"twarc2 dehydrate download/{0} dehydrate/{1}.txt\\n\".format(file,file.split('.')[0]))\n",
    "        # fscript.write(\"twarc2 conversations --archive {0}.txt > {1} \\n\".format(file.split('.')[0]))\n",
    "fscript.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %sh dehydrate.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscript=open(\"hydrate/hydrate.sh\",'w')\n",
    "for file in os.listdir('dehydrate'):\n",
    "    if file.split('.')[1]=='txt':\n",
    "        fscript.write(\"twarc2 hydrate dehydrate/{0} hydrate/{1}.json\\n\".format(file,file.split('.')[0]))\n",
    "        # fscript.write(\"twarc2 conversations --archive {0}.txt > {1} \\n\".format(file.split('.')[0]))\n",
    "fscript.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %sh hydrate.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('hydrate'):\n",
    "    if file.split('.')[1]=='json':\n",
    "        df=pd.read_json('hydrate/'+file,lines=True)\n",
    "        conversation_ids=[]\n",
    "        for line in df['data']:\n",
    "            for element in line:\n",
    "                if element['id']==element['conversation_id']:\n",
    "                    conversation_ids.append(element['id'])\n",
    "        print(len(set(conversation_ids)))\n",
    "        with open(\"hydrate/{0}.txt\".format(file.split('.')[0]), 'w') as fp:\n",
    "            for id in set(conversation_ids):\n",
    "                fp.write(\"%s\\n\" % id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscript=open(\"conversations/conversations.sh\",'w')\n",
    "for file in os.listdir('hydrate'):\n",
    "    if file.split('.')[1]=='txt':\n",
    "        fscript.write(\"twarc2 conversations --archive hydrate/{0} conversations/{1}.json\\n\".format(file,file.split('.')[0]))\n",
    "fscript.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %sh conversations.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to extend the conversation_ids collected not only from \"data\", but also from \"includes\". This way we get independent tweets of users mentioninig ICRC, on which they got replies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('hydrate'):\n",
    "    if file.split('.')[1]=='json':\n",
    "        df=pd.read_json('hydrate/'+file,lines=True)\n",
    "        conversation_ids=[]\n",
    "        for line in df['includes']:\n",
    "            for element in line[\"tweets\"]:\n",
    "                conversation_ids.append(element['conversation_id'])\n",
    "        print(len(set(conversation_ids)))\n",
    "        with open(\"hydrate/Extended_{0}.txt\".format(file.split('.')[0]), 'w') as fp:\n",
    "            for id in set(conversation_ids):\n",
    "                fp.write(\"%s\\n\" % id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGO_list = [\"Australia_ids\", \"Britain_ids\", \"Canada_ids\", \"Ireland_ids\", \"Nairobi_ids\", \"nepal_ids\", \"RedCrossLebanon\", \"RedCross\", \"philredcross\", \"IFRC_Europe\", \"ICRC_library\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ngo in NGO_list:\n",
    "    df_initial = pd.read_csv(\"hydrate/{file}.txt\".format(file=ngo), delimiter=\"\\t\", header = None)\n",
    "    df_extended = pd.read_csv(\"hydrate/Extended_{file}.txt\".format(file=ngo), delimiter=\"\\t\", header = None)\n",
    "    new_ids = pd.concat([df_extended, df_initial, df_initial]).drop_duplicates(keep=False)\n",
    "    new_ids.to_csv(\"conversations_extended/New_{file}.txt\".format(file=ngo), header=None, index=None)\n",
    "    print(len(new_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscript=open(\"conversations_extended/conversations_extended.sh\",'w')\n",
    "for file in os.listdir('conversations_extended'):\n",
    "    if file.split('.')[1]=='txt':\n",
    "        fscript.write(\"twarc2 conversations --archive conversations_extended/{0} conversations_extended/{1}.json\\n\".format(file,file.split('.')[0]))\n",
    "fscript.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semester_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9215884f317b28951366236cef9f8992a096a5b1fa6c5fa4d454321ff0331c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
