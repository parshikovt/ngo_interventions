{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_preprocess(path):\n",
    "    df=pd.read_csv(path,index_col=0,dtype='str')\n",
    "    df=df.dropna().copy()\n",
    "    df.index=pd.RangeIndex(start=0, stop=df.shape[0], step=1)\n",
    "    indices_1=df[df[\"label\"]==\"1\"].index\n",
    "    indices_0=df[df[\"label\"]==\"0\"].index\n",
    "    df[\"label\"]=df[\"label\"].apply(int)\n",
    "\n",
    "    df['author_rate']=(df['author_followers'].apply(float)+0.0001)/(df['author_following'].apply(float)+0.0001)\n",
    "    df['mentioned']=df['num_NGO_mentions'].apply(lambda x: int(int(x)>0))\n",
    "    # df['question']=df['num_question'].apply(lambda x: int(int(x)>0))\n",
    "    df['sentiment']=df['sentiment'].apply(lambda x: -1 if x=='negative' else (0 if x=='neutral' else 1))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res=pd.DataFrame(columns=[\"name\",\"features\",\"DT\",\"RF\",\"LR\",\"SVM\",\"NB\"])\n",
    "res=pd.read_csv(\"results/res.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_models(X_scaled,y,X_scaled_svm,y_svm):\n",
    "    clf = DecisionTreeClassifier(random_state=0,class_weight=\"balanced\")\n",
    "    res_dt=cross_val_score(clf, X_scaled, y, cv=10,scoring='balanced_accuracy')\n",
    "    print(\"Decision Tree:\\n\",res_dt,'\\n',res_dt.mean())\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=0,class_weight=\"balanced\")\n",
    "    res_rf=cross_val_score(clf, X_scaled, y, cv=10,scoring='balanced_accuracy')\n",
    "    print(\"RandomForest:\\n\",res_rf,'\\n',res_rf.mean())\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0,class_weight=\"balanced\")\n",
    "    res_lr=cross_val_score(clf, X_scaled, y, cv=10,scoring='balanced_accuracy')\n",
    "    print(\"Logistic Regression:\\n\",res_lr,'\\n',res_lr.mean())\n",
    "    \n",
    "    clf = SVC(random_state=0,class_weight=\"balanced\")\n",
    "    res_svm=cross_val_score(clf, X_scaled_svm, y_svm, cv=5,scoring='balanced_accuracy',n_jobs=-1)\n",
    "    print(\"SVM:\\n\",res_svm,'\\n',res_svm.mean())\n",
    "    \n",
    "    clf=GaussianNB()\n",
    "    res_nb=cross_val_score(clf, X_scaled, y, cv=10,scoring='balanced_accuracy')\n",
    "    print(\"Naive Bayesian:\\n\",res_nb,'\\n',res_nb.mean())\n",
    "    \n",
    "    return res_dt.mean(),res_rf.mean(),res_lr.mean(),res_svm.mean(),res_nb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(df,features,large=True):\n",
    "    X=df[features]\n",
    "    scaler = preprocessing.StandardScaler().fit(X)\n",
    "    scaler\n",
    "\n",
    "    X_scaled = scaler.transform(X)\n",
    "    y=df['label']\n",
    "\n",
    "    df_svm=df.sample(frac=0.4).copy()\n",
    "    X_svm=df_svm[features]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X)\n",
    "    scaler\n",
    "\n",
    "    X_scaled_svm = scaler.transform(X_svm)\n",
    "\n",
    "    y_svm=df_svm['label']\n",
    "    \n",
    "    if large:\n",
    "        return X_scaled,y,X_scaled_svm,y_svm\n",
    "    else:\n",
    "        return X_scaled,y,X_scaled,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_res(res,name,features,dt,rf,lr,svm,nb):\n",
    "    t=pd.DataFrame([name,features,dt,rf,lr,svm,nb]).transpose()\n",
    "    t.columns=[\"name\",\"features\",\"DT\",\"RF\",\"LR\",\"SVM\",\"NB\"]\n",
    "    res=pd.concat([res,t])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['author_rate','num_full_words','num_tokenized_words','mentioned','num_hashtags','attachment','num_NGO_mentions','num_mentions','num_exclamation', 'has_question','sentiment','retweet','topic','num_characters']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"ngos\"\n",
    "path='datasets/extended_features.csv'\n",
    "df=read_preprocess(path)\n",
    "X,y,X_svm,y_svm=get_x_y(df,features,large=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      " [0.5283885  0.54468775 0.54487394 0.52345509 0.53862533 0.53173144\n",
      " 0.52151593 0.51723246 0.52944901 0.51536283] \n",
      " 0.5295322292862142\n",
      "RandomForest:\n",
      " [0.50949537 0.51415873 0.51390241 0.50681239 0.51718424 0.50787127\n",
      " 0.50667357 0.50982134 0.50402519 0.5099    ] \n",
      " 0.5099844516323297\n",
      "Logistic Regression:\n",
      " [0.68681215 0.73871603 0.68919575 0.64472495 0.65242756 0.62504626\n",
      " 0.6346866  0.54705454 0.62337462 0.58223054] \n",
      " 0.6424269007971002\n",
      "SVM:\n",
      " [0.68017502 0.70157153 0.70049634 0.67371319 0.67365694] \n",
      " 0.6859226024205711\n",
      "Naive Bayesian:\n",
      " [0.54580261 0.55623465 0.5185099  0.53070721 0.51983883 0.51075848\n",
      " 0.53320401 0.52840541 0.51726444 0.53828532] \n",
      " 0.5299010843071603\n"
     ]
    }
   ],
   "source": [
    "dt,rf,lr,svm,nb=run_all_models(X,y,X_svm,y_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=add_res(res,name,features,dt,rf,lr,svm,nb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21659, 28)\n"
     ]
    }
   ],
   "source": [
    "name=\"banks\"\n",
    "path='datasets/Banks_extended_features.csv'\n",
    "df=read_preprocess(path)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['has_question', 'retweet', 'topic', 'num_characters'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X,y,X_svm,y_svm\u001b[39m=\u001b[39mget_x_y(df,features,large\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m, in \u001b[0;36mget_x_y\u001b[1;34m(df, features, large)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_x_y\u001b[39m(df,features,large\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m----> 2\u001b[0m     X\u001b[39m=\u001b[39mdf[features]\n\u001b[0;32m      3\u001b[0m     scaler \u001b[39m=\u001b[39m preprocessing\u001b[39m.\u001b[39mStandardScaler()\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m      4\u001b[0m     scaler\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\semester_project\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\semester_project\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\semester_project\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['has_question', 'retweet', 'topic', 'num_characters'] not in index\""
     ]
    }
   ],
   "source": [
    "X,y,X_svm,y_svm=get_x_y(df,features,large=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      " [0.5911189  0.57064709 0.58232545 0.60430909 0.57928025 0.59189586\n",
      " 0.54796305 0.63845408 0.64044799 0.55796493] \n",
      " 0.5904406686818795\n",
      "RandomForest:\n",
      " [0.56645486 0.5555872  0.58562664 0.58225241 0.5665495  0.57384638\n",
      " 0.55981624 0.65927443 0.64858487 0.59079893] \n",
      " 0.5888791467406074\n",
      "Logistic Regression:\n",
      " [0.60725241 0.59505551 0.66401548 0.72060327 0.62790633 0.66172895\n",
      " 0.64795457 0.69357341 0.70590175 0.60817805] \n",
      " 0.6532169731612386\n",
      "SVM:\n",
      " [0.60881726 0.69064718 0.63789021 0.67351753 0.65696764] \n",
      " 0.6535679660299089\n",
      "Naive Bayesian:\n",
      " [0.57392638 0.5634385  0.61069968 0.63706544 0.59987637 0.61774282\n",
      " 0.59941698 0.59314311 0.62817663 0.58687736] \n",
      " 0.6010363261277301\n"
     ]
    }
   ],
   "source": [
    "dt,rf,lr,svm,nb=run_all_models(X,y,X_svm,y_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=add_res(res,name,features,dt,rf,lr,svm,nb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21659, 29)\n"
     ]
    }
   ],
   "source": [
    "name=\"airlines\"\n",
    "path='datasets/Airlines_extended_features.csv'\n",
    "print(df.shape)\n",
    "df=read_preprocess(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,X_svm,y_svm=get_x_y(df,features,large=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      " [0.56266831 0.56872059 0.54406571 0.57191244 0.57794528 0.57231014\n",
      " 0.56456225 0.54863199 0.58803602 0.57135109] \n",
      " 0.5670203831010882\n",
      "RandomForest:\n",
      " [0.61218919 0.5991418  0.58516498 0.578504   0.60077805 0.56876206\n",
      " 0.5843196  0.57905718 0.61848971 0.62858299] \n",
      " 0.5954989562064834\n",
      "Logistic Regression:\n",
      " [0.59925991 0.62500938 0.58476103 0.52085329 0.59498744 0.64919696\n",
      " 0.5551368  0.59230347 0.65234629 0.68657696] \n",
      " 0.606043154227161\n",
      "SVM:\n",
      " [0.64003673 0.59546511 0.6551309  0.61535816 0.67260289] \n",
      " 0.6357187591533684\n",
      "Naive Bayesian:\n",
      " [0.54816813 0.56932506 0.54101181 0.52455961 0.57872472 0.5400422\n",
      " 0.52570274 0.53223254 0.53955405 0.53066089] \n",
      " 0.5429981751437661\n"
     ]
    }
   ],
   "source": [
    "dt,rf,lr,svm,nb=run_all_models(X,y,X_svm,y_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=add_res(res,name,features,dt,rf,lr,svm,nb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67420, 29)\n"
     ]
    }
   ],
   "source": [
    "name=\"icrc\"\n",
    "path='datasets/ICRC_extended_features.csv'\n",
    "df=read_preprocess(path)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['retweet', 'topic', 'num_characters'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X,y,X_svm,y_svm\u001b[39m=\u001b[39mget_x_y(df,features,large\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m, in \u001b[0;36mget_x_y\u001b[1;34m(df, features, large)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_x_y\u001b[39m(df,features,large\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m----> 2\u001b[0m     X\u001b[39m=\u001b[39mdf[features]\n\u001b[0;32m      3\u001b[0m     scaler \u001b[39m=\u001b[39m preprocessing\u001b[39m.\u001b[39mStandardScaler()\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m      4\u001b[0m     scaler\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\semester_project\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\semester_project\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\semester_project\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['retweet', 'topic', 'num_characters'] not in index\""
     ]
    }
   ],
   "source": [
    "X,y,X_svm,y_svm=get_x_y(df,features,large=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      " [0.58763965 0.5712159  0.5542945  0.55288096 0.5619915  0.54767014\n",
      " 0.55271906 0.54904524 0.55729979 0.57411709] \n",
      " 0.5608873831674795\n",
      "RandomForest:\n",
      " [0.58245666 0.57275185 0.56331641 0.54808787 0.57353816 0.54421357\n",
      " 0.55424165 0.55633515 0.54954146 0.57229431] \n",
      " 0.5616777089782194\n",
      "Logistic Regression:\n",
      " [0.73921577 0.78067686 0.72209115 0.65046835 0.66931671 0.63179505\n",
      " 0.63524715 0.6541867  0.59148127 0.74500116] \n",
      " 0.6819480161493902\n",
      "SVM:\n",
      " [0.74682601 0.71373701 0.67662393 0.65049841 0.71330208] \n",
      " 0.7001974877417465\n",
      "Naive Bayesian:\n",
      " [0.64282075 0.70194947 0.65526286 0.63641373 0.66052965 0.54556698\n",
      " 0.53690574 0.55088262 0.5412485  0.57498182] \n",
      " 0.6046562122538796\n"
     ]
    }
   ],
   "source": [
    "dt,rf,lr,svm,nb=run_all_models(X,y,X_svm,y_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=add_res(res,name,features,dt,rf,lr,svm,nb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other NGOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48058, 30)\n"
     ]
    }
   ],
   "source": [
    "name=\"other_ngos\"\n",
    "path='datasets/OtherNGO_extended_features.csv'\n",
    "df=read_preprocess(path)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,X_svm,y_svm=get_x_y(df,features,large=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      " [0.49936143 0.50947212 0.51426139 0.50757852 0.51715911 0.5120397\n",
      " 0.49594608 0.57048223 0.5658675  0.49561974] \n",
      " 0.5187787809528526\n",
      "RandomForest:\n",
      " [0.48919753 0.4902086  0.49856322 0.50302946 0.50485865 0.50186826\n",
      " 0.49824893 0.54292023 0.51984423 0.49088957] \n",
      " 0.5039628687465282\n",
      "Logistic Regression:\n",
      " [0.4691358  0.63197105 0.63633461 0.56557865 0.55455659 0.59193161\n",
      " 0.55982151 0.54326302 0.6208011  0.54283073] \n",
      " 0.5716224679004711\n",
      "SVM:\n",
      " [0.48806282 0.6303657  0.60370528 0.62316716 0.58632483] \n",
      " 0.586325156754284\n",
      "Naive Bayesian:\n",
      " [0.56758195 0.50771605 0.50723712 0.56165755 0.53738576 0.55576368\n",
      " 0.54491155 0.50951515 0.54766242 0.51653636] \n",
      " 0.5355967590748814\n"
     ]
    }
   ],
   "source": [
    "dt,rf,lr,svm,nb=run_all_models(X,y,X_svm,y_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=add_res(res,name,features,dt,rf,lr,svm,nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>features</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>LR</th>\n",
       "      <th>SVM</th>\n",
       "      <th>NB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ngos</td>\n",
       "      <td>['author_rate', 'num_full_words', 'num_tokeniz...</td>\n",
       "      <td>0.549477</td>\n",
       "      <td>0.546262</td>\n",
       "      <td>0.636432</td>\n",
       "      <td>0.671548</td>\n",
       "      <td>0.567851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banks</td>\n",
       "      <td>['author_rate', 'num_full_words', 'num_tokeniz...</td>\n",
       "      <td>0.590441</td>\n",
       "      <td>0.588879</td>\n",
       "      <td>0.653217</td>\n",
       "      <td>0.653568</td>\n",
       "      <td>0.601036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airlines</td>\n",
       "      <td>['author_rate', 'num_full_words', 'num_tokeniz...</td>\n",
       "      <td>0.56702</td>\n",
       "      <td>0.595499</td>\n",
       "      <td>0.606043</td>\n",
       "      <td>0.635719</td>\n",
       "      <td>0.542998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>icrc</td>\n",
       "      <td>['author_rate', 'num_full_words', 'num_tokeniz...</td>\n",
       "      <td>0.560887</td>\n",
       "      <td>0.561678</td>\n",
       "      <td>0.681948</td>\n",
       "      <td>0.700197</td>\n",
       "      <td>0.604656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other_ngos</td>\n",
       "      <td>['author_rate', 'num_full_words', 'num_tokeniz...</td>\n",
       "      <td>0.518779</td>\n",
       "      <td>0.503963</td>\n",
       "      <td>0.571622</td>\n",
       "      <td>0.586325</td>\n",
       "      <td>0.535597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ngos</td>\n",
       "      <td>[author_rate, num_full_words, num_tokenized_wo...</td>\n",
       "      <td>0.529532</td>\n",
       "      <td>0.509984</td>\n",
       "      <td>0.642427</td>\n",
       "      <td>0.685923</td>\n",
       "      <td>0.529901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name                                           features        DT  \\\n",
       "0        ngos  ['author_rate', 'num_full_words', 'num_tokeniz...  0.549477   \n",
       "1       banks  ['author_rate', 'num_full_words', 'num_tokeniz...  0.590441   \n",
       "2    airlines  ['author_rate', 'num_full_words', 'num_tokeniz...   0.56702   \n",
       "3        icrc  ['author_rate', 'num_full_words', 'num_tokeniz...  0.560887   \n",
       "4  other_ngos  ['author_rate', 'num_full_words', 'num_tokeniz...  0.518779   \n",
       "0        ngos  [author_rate, num_full_words, num_tokenized_wo...  0.529532   \n",
       "\n",
       "         RF        LR       SVM        NB  \n",
       "0  0.546262  0.636432  0.671548  0.567851  \n",
       "1  0.588879  0.653217  0.653568  0.601036  \n",
       "2  0.595499  0.606043  0.635719  0.542998  \n",
       "3  0.561678  0.681948  0.700197  0.604656  \n",
       "4  0.503963  0.571622  0.586325  0.535597  \n",
       "0  0.509984  0.642427  0.685923  0.529901  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('results/res.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semester_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9215884f317b28951366236cef9f8992a096a5b1fa6c5fa4d454321ff0331c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
